// FaceAnalyzer.kt
package com.example.canhbaongugat

import android.content.Context
import android.graphics.Bitmap
import android.graphics.PointF // ‚úÖ TH√äM L·∫†I
import android.graphics.Rect
import android.util.Log
import androidx.annotation.OptIn
import androidx.camera.core.ExperimentalGetImage
import androidx.camera.core.ImageAnalysis
import androidx.camera.core.ImageProxy
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.Face
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import com.google.mlkit.vision.face.FaceLandmark // ‚úÖ TH√äM L·∫†I
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import org.tensorflow.lite.DataType
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.support.common.FileUtil
import org.tensorflow.lite.support.common.ops.NormalizeOp
import org.tensorflow.lite.support.image.ImageProcessor
import org.tensorflow.lite.support.image.TensorImage
import org.tensorflow.lite.support.image.ops.ResizeOp
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer
import java.nio.ByteBuffer
import java.util.concurrent.TimeUnit
import kotlin.math.max
import kotlin.math.min
import kotlin.math.pow // ‚úÖ TH√äM L·∫†I
import kotlin.math.sqrt // ‚úÖ TH√äM L·∫†I


// üîî C√°c c·∫•p ƒë·ªô c·∫£nh b√°o (Kh√¥ng ƒë·ªïi)
enum class AlertLevel {
    NONE,
    LOW,
    CRITICAL
}

// ‚úÖ PHI√äN B·∫¢N K·∫æT H·ª¢P (ML Kit + TFLite + Ng√°p)
class FaceAnalyzer(context: Context) : ImageAnalysis.Analyzer {

    // üå° Tr·∫°ng th√°i (Kh√¥ng ƒë·ªïi)
    private val _alertLevel = MutableStateFlow(AlertLevel.NONE)
    val alertLevel: StateFlow<AlertLevel> = _alertLevel
    private val _currentOpenness = MutableStateFlow(1.0)
    val currentOpenness: StateFlow<Double> = _currentOpenness
    // ‚úÖ TH√äM L·∫†I: Tr·∫°ng th√°i mi·ªáng
    private val _currentMouthRatio = MutableStateFlow(0.0)
    val currentMouthRatio: StateFlow<Double> = _currentMouthRatio

    // üö¶ Ng∆∞·ª°ng c·∫£nh b√°o (C·∫≠p nh·∫≠t)
    private val LOW_DROWSY_THRESHOLD = 0.50
    private val CRITICAL_DROWSY_THRESHOLD = 0.30
    private val YAWN_THRESHOLD = 0.60 // ‚úÖ TH√äM L·∫†I: Ng∆∞·ª°ng ng√°p
    private val LOW_DROWSY_FRAMES = 10
    private val CRITICAL_DROWSY_FRAMES = 30
    private var frameCounter = 0
    private var lastAnalyzedTimestamp = 0L

    // --- ‚úÖ 1. B·ªò PH√ÅT HI·ªÜN KHU√îN M·∫∂T (ML Kit) ---
    private val faceDetectorOptions = FaceDetectorOptions.Builder()
        .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)
        .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL) // ‚úÖ C·∫ßn Landmark cho mi·ªáng
        .build()
    private val faceDetector = FaceDetection.getClient(faceDetectorOptions)

    // --- ‚úÖ 2. B·ªò PH√ÇN LO·∫†I ·∫¢NH (TFLite) ---
    private val tfliteInterpreter: Interpreter
    private val labels: List<String>
    private val imageProcessor: ImageProcessor
    private val outputBuffer: TensorBuffer
    private val MODEL_INPUT_WIDTH = 160
    private val MODEL_INPUT_HEIGHT = 160

    init {
        // --- C·∫•u h√¨nh TFLite (Kh√¥ng ƒë·ªïi) ---
        val modelByteBuffer: ByteBuffer =
            FileUtil.loadMappedFile(context, "model.tflite")
        tfliteInterpreter = Interpreter(modelByteBuffer, Interpreter.Options())
        labels = FileUtil.loadLabels(context, "labels.txt")

        val outputShape = tfliteInterpreter.getOutputTensor(0).shape()
        val outputDataType = tfliteInterpreter.getOutputTensor(0).dataType()
        outputBuffer = TensorBuffer.createFixedSize(outputShape, outputDataType)

        imageProcessor = ImageProcessor.Builder()
            .add(ResizeOp(MODEL_INPUT_HEIGHT, MODEL_INPUT_WIDTH, ResizeOp.ResizeMethod.BILINEAR))
            .add(NormalizeOp(127.5f, 127.5f)) // Chuy·ªÉn pixel v·ªÅ [-1, 1]
            .build()

        Log.i("FaceAnalyzer", "ƒê√£ kh·ªüi t·∫°o TFLite v√† ML Kit Face Detector (c√≥ Landmark)")
    }

    @OptIn(ExperimentalGetImage::class)
    override fun analyze(imageProxy: ImageProxy) {
        val currentTimestamp = System.currentTimeMillis()
        if (currentTimestamp - lastAnalyzedTimestamp < TimeUnit.MILLISECONDS.toMillis(50)) {
            imageProxy.close()
            return
        }
        lastAnalyzedTimestamp = currentTimestamp

        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            val image = InputImage.fromMediaImage(
                mediaImage,
                imageProxy.imageInfo.rotationDegrees
            )

            // 2. CH·∫†Y ML KIT ƒê·ªÇ T√åM KHU√îN M·∫∂T
            faceDetector.process(image)
                .addOnSuccessListener { faces ->
                    if (faces.isNotEmpty()) {
                        val face = faces.first()

                        // ‚úÖ TH√äM L·∫†I: T√≠nh to√°n Mouth Aspect Ratio (MAR)
                        val mouthRatio = calculateMouthRatio(face)
                        _currentMouthRatio.value = mouthRatio // C·∫≠p nh·∫≠t UI

                        // 3. CHU·∫®N B·ªä ·∫¢NH ƒê·ªÇ C·∫ÆT (CROP)
                        val fullBitmap = imageProxy.toBitmap()

                        // 4. C·∫ÆT (CROP) ·∫¢NH
                        val croppedBitmap = cropBitmap(fullBitmap, face.boundingBox)

                        // 5. CH·∫†Y TFLite (M√¥ h√¨nh c·ªßa anh)
                        // ‚úÖ S·ª≠a: Truy·ªÅn c·∫£ mouthRatio v√†o
                        runTFLite(croppedBitmap, mouthRatio)

                    } else {
                        // Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t
                        processResult(1.0, 0.0) // M·∫Øt m·ªü, mi·ªáng ƒë√≥ng
                        _currentMouthRatio.value = 0.0
                    }
                }
                .addOnFailureListener { e ->
                    Log.e("FaceAnalyzer", "ML Kit Face Detection th·∫•t b·∫°i: ${e.message}")
                }
                .addOnCompleteListener {
                    imageProxy.close()
                }
        } else {
            imageProxy.close()
        }
    }

    /**
     * C·∫Øt Bitmap theo khung vi·ªÅn (Rect)
     */
    private fun cropBitmap(source: Bitmap, box: Rect): Bitmap {
        val left = max(0, box.left)
        val top = max(0, box.top)
        val width = min(source.width - left, box.width())
        val height = min(source.height - top, box.height())

        if (width <= 0 || height <= 0) {
            Log.w("FaceAnalyzer", "Khung c·∫Øt kh√¥ng h·ª£p l·ªá (width/height <= 0)")
            return source
        }
        return Bitmap.createBitmap(source, left, top, width, height)
    }

    /**
     * ‚úÖ TH√äM L·∫†I: T√≠nh to√°n Mouth Aspect Ratio (MAR)
     */
    private fun calculateMouthRatio(face: Face): Double {
        val mouthLeft = face.getLandmark(FaceLandmark.MOUTH_LEFT)?.position
        val mouthRight = face.getLandmark(FaceLandmark.MOUTH_RIGHT)?.position
        val mouthBottom = face.getLandmark(FaceLandmark.MOUTH_BOTTOM)?.position
        val noseBase = face.getLandmark(FaceLandmark.NOSE_BASE)?.position

        var mouthRatio = 0.0
        if (mouthLeft != null && mouthRight != null && mouthBottom != null && noseBase != null) {
            // ∆Ø·ªõc l∆∞·ª£ng MOUTH_TOP (gi·ªëng code c≈© c·ªßa anh)
            val mouthTopX = (noseBase.x + mouthBottom.x) / 2
            val mouthTopY = (noseBase.y + mouthBottom.y) / 2
            val mouthTop = PointF(mouthTopX, mouthTopY)

            val vertical = distance(mouthTop, mouthBottom)
            val horizontal = distance(mouthLeft, mouthRight)
            if (horizontal > 0) {
                mouthRatio = vertical / horizontal
            }
        }
        return mouthRatio
    }

    /**
     * ‚úÖ TH√äM L·∫†I: H√†m t√≠nh kho·∫£ng c√°ch
     */
    private fun distance(p1: PointF, p2: PointF): Double {
        return sqrt(
            (p2.x - p1.x).toDouble().pow(2.0) +
                    (p2.y - p1.y).toDouble().pow(2.0)
        )
    }


    /**
     * Ch·∫°y m√¥ h√¨nh TFLite tr√™n Bitmap ƒë√£ c·∫Øt
     */
    // ‚úÖ S·ª≠a: Th√™m tham s·ªë mouthRatio
    private fun runTFLite(bitmap: Bitmap, mouthRatio: Double) {
        val tensorImage = TensorImage.fromBitmap(bitmap)
        val processedImage = imageProcessor.process(tensorImage)

        try {
            tfliteInterpreter.run(processedImage.buffer, outputBuffer.buffer)
        } catch (e: Exception) {
            Log.e("FaceAnalyzer", "L·ªói khi ch·∫°y m√¥ h√¨nh TFLite: ${e.message}", e)
            return
        }

        val probabilityOpen = outputBuffer.floatArray[0].toDouble()

        // ‚úÖ S·ª≠a: Truy·ªÅn c·∫£ 2 k·∫øt qu·∫£
        processResult(probabilityOpen, mouthRatio)
    }

    /**
     * ‚úÖ S·ª¨A: H√ÄM LOGIC C·∫¢NH B√ÅO (D√πng c·∫£ M·∫Øt v√† Mi·ªáng)
     */
    private fun processResult(openness: Double, mouthRatio: Double) {
        _currentOpenness.value = openness
        // _currentMouthRatio ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h√†m analyze

        when {
            // üö® C·∫¢NH B√ÅO NG·ª¶ G·∫¨T (CRITICAL - M·∫Øt nh·∫Øm s√¢u)
            openness < CRITICAL_DROWSY_THRESHOLD -> {
                frameCounter++
                if (frameCounter >= CRITICAL_DROWSY_FRAMES) {
                    _alertLevel.value = AlertLevel.CRITICAL
                    Log.w("DrowsyAnalyzer", "üö® (Hybrid) PH√ÅT HI·ªÜN NG·ª¶ G·∫¨T!")
                } else if (frameCounter >= LOW_DROWSY_FRAMES) {
                    _alertLevel.value = AlertLevel.LOW
                }
            }

            // ‚ö†Ô∏è C·∫¢NH B√ÅO S·ªöM (LOW - M·∫Øt nh·∫Øm nh·∫π HO·∫∂C Ng√°p)
            // ‚úÖ TH√äM L·∫†I LOGIC NG√ÅP
            openness < LOW_DROWSY_THRESHOLD || mouthRatio > YAWN_THRESHOLD -> {
                frameCounter++
                if (frameCounter >= LOW_DROWSY_FRAMES && _alertLevel.value == AlertLevel.NONE) {
                    _alertLevel.value = AlertLevel.LOW
                    Log.i("DrowsyAnalyzer", "‚ö†Ô∏è (Hybrid) C·∫¢NH B√ÅO: M·ªát m·ªèi ho·∫∑c Ng√°p")
                }
            }

            // üëÅ TR·∫†NG TH√ÅI T·ªàNH T√ÅO (RESET)
            // ‚úÖ TH√äM L·∫†I LOGIC NG√ÅP
            openness > (LOW_DROWSY_THRESHOLD + 0.10) && mouthRatio < 0.5 -> {
                frameCounter = 0
                if (_alertLevel.value != AlertLevel.NONE) {
                    Log.i("DrowsyAnalyzer", "üëÅ (Hybrid) T·ªânh t√°o tr·ªü l·∫°i")
                }
                _alertLevel.value = AlertLevel.NONE
            }

            else -> {
                if (_alertLevel.value == AlertLevel.NONE) frameCounter = 0
            }
        }
    }

    // ‚úÖ H√ÄM PH√ÇN T√çCH ·∫¢NH Tƒ®NH (Kh√¥ng thay ƒë·ªïi)
    fun analyzeBitmap(bitmap: Bitmap): Double {
        Log.i("FaceAnalyzer", "B·∫Øt ƒë·∫ßu ph√¢n t√≠ch ·∫£nh tƒ©nh...")

        // 1. CH·∫†Y ML KIT ƒê·ªÇ T√åM KHU√îN M·∫∂T
        // (B·∫Øt bu·ªôc ph·∫£i ch·∫°y ƒë·ªÉ c·∫Øt ·∫£nh)
        val image = InputImage.fromBitmap(bitmap, 0)
        val tasks = faceDetector.process(image)

        // Ph·∫£i ch·ªù cho ML Kit ch·∫°y xong
        // ƒê√¢y l√† c√°ch ch·∫°y ƒë·ªìng b·ªô (blocking), ch·ªâ d√πng cho demo ·∫£nh tƒ©nh
        try {
            val faces = com.google.android.gms.tasks.Tasks.await(tasks)
            if (faces.isNotEmpty()) {
                val face = faces.first()
                // C·∫Øt ·∫£nh
                val croppedBitmap = cropBitmap(bitmap, face.boundingBox)

                // Ch·∫°y TFLite
                val tensorImage = TensorImage.fromBitmap(croppedBitmap)
                val processedImage = imageProcessor.process(tensorImage)

                val localOutputBuffer = TensorBuffer.createFixedSize(
                    outputBuffer.shape,
                    outputBuffer.dataType
                )
                tfliteInterpreter.run(processedImage.buffer, localOutputBuffer.buffer)
                val probabilityOpen = localOutputBuffer.floatArray[0].toDouble()
                Log.i("FaceAnalyzer", "Ph√¢n t√≠ch ·∫£nh tƒ©nh xong. X√°c su·∫•t M·∫Øt M·ªü: $probabilityOpen")
                return probabilityOpen
            } else {
                Log.w("FaceAnalyzer", "·∫¢nh tƒ©nh kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t.")
                return 1.0 // Kh√¥ng th·∫•y m·∫∑t, coi nh∆∞ t·ªânh
            }
        } catch (e: Exception) {
            Log.e("FaceAnalyzer", "L·ªói khi ph√¢n t√≠ch ·∫£nh tƒ©nh: ${e.message}", e)
            return 1.0 // L·ªói, coi nh∆∞ t·ªânh
        }
    }
}